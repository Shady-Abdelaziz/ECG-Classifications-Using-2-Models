{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Importing Libraries and Dataset\n"
      ],
      "metadata": {
        "id": "vEFYUcOJWE4y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ532FLFz7Zh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import zipfile\n",
        "!pip install xgboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qNuN6afCsST"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler , StandardScaler , PowerTransformer\n",
        "from sklearn.model_selection import train_test_split ,  KFold , cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB , BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix , accuracy_score , precision_score, recall_score, f1_score , ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!pip install kaggle\n",
        "!kaggle datasets download -d shayanfazeli/heartbeat\n",
        "!unzip heartbeat.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tEZUJn8q7fk",
        "outputId": "db274764-2c9f-43ff-dbd6-39d6e32a5a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/shayanfazeli/heartbeat\n",
            "License(s): unknown\n",
            "Downloading heartbeat.zip to /content\n",
            " 97% 96.0M/98.8M [00:00<00:00, 224MB/s]\n",
            "100% 98.8M/98.8M [00:00<00:00, 199MB/s]\n",
            "Archive:  heartbeat.zip\n",
            "  inflating: mitbih_test.csv         \n",
            "  inflating: mitbih_train.csv        \n",
            "  inflating: ptbdb_abnormal.csv      \n",
            "  inflating: ptbdb_normal.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7M5vRi8ZNM2"
      },
      "source": [
        "### No sampling log reg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTMsFYVv2R-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132a5587-33f5-47f4-c574-a1ecd96ce39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: Counter({0.0: 72471, 4.0: 6431, 2.0: 5788, 1.0: 2223, 3.0: 641})\n",
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.63      0.77     18118\n",
            "         1.0       0.14      0.65      0.23       556\n",
            "         2.0       0.27      0.75      0.40      1448\n",
            "         3.0       0.09      0.86      0.16       162\n",
            "         4.0       0.76      0.90      0.82      1608\n",
            "\n",
            "    accuracy                           0.66     21892\n",
            "   macro avg       0.45      0.76      0.48     21892\n",
            "weighted avg       0.88      0.66      0.73     21892\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "x_train = train.iloc[:, :100]\n",
        "y_train = train.iloc[:, 187]\n",
        "x_test = test.iloc[:, :100]\n",
        "y_test = test.iloc[:, 187]\n",
        "\n",
        "print(f\"Original dataset shape: {Counter(y_train)}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "\n",
        "log_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred = log_reg.predict(x_test)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TLbLePuXUVn"
      },
      "source": [
        "### ***Binary classifier log reg***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-6R69uh2SDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1aa932e-fc84-4816-e6fe-b991d9181458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: Counter({1: 72471, 0: 15083})\n",
            "Classification Report for Logistic Regression (Binary Classification):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.76      0.62      3774\n",
            "           1       0.94      0.86      0.90     18118\n",
            "\n",
            "    accuracy                           0.84     21892\n",
            "   macro avg       0.73      0.81      0.76     21892\n",
            "weighted avg       0.87      0.84      0.85     21892\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "x = train.iloc[:, :100]\n",
        "y = train.iloc[:, 187]\n",
        "\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "x_test = test.iloc[:, :100]\n",
        "y_test = test.iloc[:, 187]\n",
        "\n",
        "y_test_binary = (y_test == 0).astype(int)\n",
        "\n",
        "print(f\"Original dataset shape: {Counter(y_binary)}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "log_reg.fit(x_scaled, y_binary)\n",
        "\n",
        "y_pred = log_reg.predict(x_test_scaled)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Binary Classification):\")\n",
        "print(classification_report(y_test_binary, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfYlyi0TecUE"
      },
      "source": [
        "### Random Forrest 5 cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1vmBm1f2SGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c91d04da-dd55-45ce-8e1d-2f860cbeca85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: Counter({0.0: 72471, 4.0: 6431, 2.0: 5788, 1.0: 2223, 3.0: 641})\n",
            "Classification Report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      1.00      0.99     18118\n",
            "         1.0       0.96      0.59      0.73       556\n",
            "         2.0       0.98      0.88      0.93      1448\n",
            "         3.0       0.83      0.59      0.69       162\n",
            "         4.0       0.99      0.95      0.97      1608\n",
            "\n",
            "    accuracy                           0.97     21892\n",
            "   macro avg       0.95      0.80      0.86     21892\n",
            "weighted avg       0.97      0.97      0.97     21892\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "x_train = train.iloc[:, :100]\n",
        "y_train = train.iloc[:, 187]\n",
        "x_test = test.iloc[:, :100]\n",
        "y_test = test.iloc[:, 187]\n",
        "\n",
        "print(f\"Original dataset shape: {Counter(y_train)}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
        "\n",
        "rf_model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = rf_model.predict(x_test)\n",
        "\n",
        "print(\"Classification Report for Random Forest:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oFj2w0fpA8F"
      },
      "source": [
        "### 2 models Random Forrest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EirsQIqZobqH",
        "outputId": "f13999e1-9a1d-4061-cdf9-c33a4fbbaccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Model (Binary Classification):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.88      0.93      3774\n",
            "           1       0.98      1.00      0.99     18118\n",
            "\n",
            "    accuracy                           0.98     21892\n",
            "   macro avg       0.98      0.94      0.96     21892\n",
            "weighted avg       0.98      0.98      0.98     21892\n",
            "\n",
            "ROC-AUC Score: 0.94\n"
          ]
        }
      ],
      "source": [
        "# Phase 1\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "X_train, y_train = train.iloc[:, :100], train.iloc[:, 187]\n",
        "X_test, y_test = test.iloc[:, :100], test.iloc[:, 187]\n",
        "\n",
        "y_train_binary = (y_train == 0).astype(int)\n",
        "y_test_binary = (y_test == 0).astype(int)\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train_binary)\n",
        "\n",
        "print(\"First Model (Binary Classification):\")\n",
        "y_pred_binary = rf_model.predict(X_test)\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test_binary, y_pred_binary):.2f}\")\n",
        "\n",
        "y_train_pred_binary = rf_model.predict(X_train)\n",
        "y_test_pred_binary = rf_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztn21oF2tfcM",
        "outputId": "76d8f7e6-05be-4262-8a2b-5f4006b9b35f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in training set:\n",
            "187\n",
            "0.0    72471\n",
            "4.0     6431\n",
            "2.0     5788\n",
            "1.0     2223\n",
            "3.0      641\n",
            "Name: count, dtype: int64\n",
            "Number of subclass samples in training set: 15083\n",
            "Number of subclass samples in test set: 3774\n",
            "Second Model (Multi-Class Classification with Class Weights):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.97      0.93      0.95       556\n",
            "         2.0       0.95      0.98      0.96      1448\n",
            "         3.0       0.85      0.80      0.83       162\n",
            "         4.0       0.99      0.98      0.99      1608\n",
            "\n",
            "    accuracy                           0.96      3774\n",
            "   macro avg       0.94      0.92      0.93      3774\n",
            "weighted avg       0.96      0.96      0.96      3774\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Phase 2 no over sample\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "X_train, y_train = train.iloc[:, :100], train.iloc[:, 187]\n",
        "X_test, y_test = test.iloc[:, :100], test.iloc[:, 187]\n",
        "\n",
        "print(\"Class distribution in training set:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "X_train_subclass = X_train[y_train.isin([1, 2, 3, 4])]\n",
        "y_train_subclass = y_train[y_train.isin([1, 2, 3, 4])]\n",
        "\n",
        "X_test_subclass = X_test[y_test.isin([1, 2, 3, 4])]\n",
        "y_test_subclass = y_test[y_test.isin([1, 2, 3, 4])]\n",
        "\n",
        "print(f\"Number of subclass samples in training set: {y_train_subclass.shape[0]}\")\n",
        "print(f\"Number of subclass samples in test set: {y_test_subclass.shape[0]}\")\n",
        "\n",
        "if y_train_subclass.shape[0] > 0:\n",
        "    class_weights = {\n",
        "        1: 2.0,\n",
        "        2: 2.0,\n",
        "        3: 20.0,\n",
        "        4: 2.0\n",
        "    }\n",
        "\n",
        "    rf_model_subclass = RandomForestClassifier(\n",
        "\n",
        "        class_weight=class_weights,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    rf_model_subclass.fit(X_train_subclass, y_train_subclass)\n",
        "\n",
        "    print(\"Second Model (Multi-Class Classification with Class Weights):\")\n",
        "    y_pred_subclass = rf_model_subclass.predict(X_test_subclass)\n",
        "    print(classification_report(y_test_subclass, y_pred_subclass))\n",
        "else:\n",
        "    print(\"No samples available for training the subclass model.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Over Sample"
      ],
      "metadata": {
        "id": "tovXQ3xIEMTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "X_train, y_train = train.iloc[:, :100], train.iloc[:, 187]\n",
        "X_test, y_test = test.iloc[:, :100], test.iloc[:, 187]\n",
        "\n",
        "print(\"Class distribution in training set:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "X_train_subclass = X_train[y_train.isin([1, 2, 3, 4])]\n",
        "y_train_subclass = y_train[y_train.isin([1, 2, 3, 4])]\n",
        "\n",
        "X_test_subclass = X_test[y_test.isin([1, 2, 3, 4])]\n",
        "y_test_subclass = y_test[y_test.isin([1, 2, 3, 4])]\n",
        "\n",
        "print(f\"Number of subclass samples in training set: {y_train_subclass.shape[0]}\")\n",
        "print(f\"Number of subclass samples in test set: {y_test_subclass.shape[0]}\")\n",
        "\n",
        "smote = SMOTE(sampling_strategy={3: 7000}, random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_subclass, y_train_subclass)\n",
        "\n",
        "class_weights = {\n",
        "        1: 2.0,\n",
        "        2: 2.0,\n",
        "        3: 20.0,\n",
        "        4: 2.0\n",
        "    }\n",
        "\n",
        "rf_model_subclass = RandomForestClassifier(\n",
        "        max_depth=None,\n",
        "        class_weight=class_weights,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "rf_model_subclass.fit(X_resampled, y_resampled)\n",
        "\n",
        "print(\"Second Model (Multi-Class Classification with Class Weights):\")\n",
        "    y_pred_subclass = rf_model_subclass.predict(X_test_subclass)\n",
        "print(classification_report(y_test_subclass, y_pred_subclass))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvF-5MjzEK5f",
        "outputId": "ef7c6b1d-cc35-4cdd-c72d-849151f1a984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Class distribution in training set:\n",
            "187\n",
            "0.0    72471\n",
            "4.0     6431\n",
            "2.0     5788\n",
            "1.0     2223\n",
            "3.0      641\n",
            "Name: count, dtype: int64\n",
            "Number of subclass samples in training set: 15083\n",
            "Number of subclass samples in test set: 3774\n",
            "Second Model (Multi-Class Classification with Class Weights):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.97      0.92      0.94       556\n",
            "         2.0       0.95      0.97      0.96      1448\n",
            "         3.0       0.82      0.88      0.85       162\n",
            "         4.0       0.99      0.98      0.99      1608\n",
            "\n",
            "    accuracy                           0.96      3774\n",
            "   macro avg       0.93      0.94      0.93      3774\n",
            "weighted avg       0.96      0.96      0.96      3774\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 Models  Xgboost  (Best One)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tRbGu40LvG_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#phase 1\n",
        "!pip install imbalanced-learn\n",
        "!pip install xgboost\n",
        "\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "X_train, y_train = train.iloc[:, :100], train.iloc[:, 187]\n",
        "X_test, y_test = test.iloc[:, :100], test.iloc[:, 187]\n",
        "\n",
        "y_train_binary = (y_train != 0).astype(int)\n",
        "y_test_binary = (y_test != 0).astype(int)\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train_binary)\n",
        "\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "y_pred_binary = xgb_model.predict(X_test)\n",
        "\n",
        "print(\"XGBoost Model (Binary Classification):\")\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n"
      ],
      "metadata": {
        "id": "KXwUa7YwE79I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf6bdaa-4d88-47b6-f0e9-ac7fb4be8e62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:12:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model (Binary Classification):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     18118\n",
            "           1       0.93      0.93      0.93      3774\n",
            "\n",
            "    accuracy                           0.98     21892\n",
            "   macro avg       0.96      0.96      0.96     21892\n",
            "weighted avg       0.98      0.98      0.98     21892\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Phase 2\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "X_train, y_train = train.iloc[:, :100], train.iloc[:, 187]\n",
        "X_test, y_test = test.iloc[:, :100], test.iloc[:, 187]\n",
        "\n",
        "X_train_subclass = X_train[y_train.isin([1, 2, 3, 4])]\n",
        "y_train_subclass = y_train[y_train.isin([1, 2, 3, 4])] - 1\n",
        "X_test_subclass = X_test[y_test.isin([1, 2, 3, 4])]\n",
        "y_test_subclass = y_test[y_test.isin([1, 2, 3, 4])]  - 1\n",
        "\n",
        "print(\"Class distribution in training set:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(f\"Number of subclass samples in training set: {y_train_subclass.shape[0]}\")\n",
        "print(f\"Number of subclass samples in test set: {y_test_subclass.shape[0]}\")\n",
        "\n",
        "smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_subclass, y_train_subclass)\n",
        "print(\"Resampled training data distribution:\", Counter(y_resampled))\n",
        "\n",
        "\n",
        "\n",
        "Abnormal_model = XGBClassifier(objective='multi:softmax',\n",
        "                          num_class=4,\n",
        "                          random_state=42,\n",
        "                          eval_metric='logloss',\n",
        "                          n_estimators = 1000 ,\n",
        "                          learning_rate = .1 ,\n",
        "                          subsample =.8 ,\n",
        "                          colsample_bytree = .8 ,\n",
        "                          max_depth = 6)\n",
        "\n",
        "\n",
        "Abnormal_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "y_pred_subclass = Abnormal_model.predict(X_test_subclass) + 1\n",
        "\n",
        "\n",
        "print(\"Model Performance (XGBoost with SMOTE - Custom Strategy):\")\n",
        "print(classification_report(y_test_subclass + 1, y_pred_subclass))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c0UCb7OvUXS",
        "outputId": "853e3f1d-b600-43d7-e209-2b90ab6f2758"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in training set:\n",
            "187\n",
            "0.0    72471\n",
            "4.0     6431\n",
            "2.0     5788\n",
            "1.0     2223\n",
            "3.0      641\n",
            "Name: count, dtype: int64\n",
            "Number of subclass samples in training set: 15083\n",
            "Number of subclass samples in test set: 3774\n",
            "Resampled training data distribution: Counter({0.0: 6431, 1.0: 6431, 2.0: 6431, 3.0: 6431})\n",
            "Model Performance (XGBoost with SMOTE - Custom Strategy):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.98      0.95      0.96       556\n",
            "         2.0       0.97      0.97      0.97      1448\n",
            "         3.0       0.81      0.91      0.85       162\n",
            "         4.0       0.99      0.99      0.99      1608\n",
            "\n",
            "    accuracy                           0.97      3774\n",
            "   macro avg       0.94      0.95      0.94      3774\n",
            "weighted avg       0.97      0.97      0.97      3774\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving Models"
      ],
      "metadata": {
        "id": "10rSEq7dja-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('xgb_model.pkl', 'wb') as f:\n",
        "    pickle.dump(rf_model, f)\n",
        "\n",
        "with open('Abnormal_model.pkl', 'wb') as f:\n",
        "    pickle.dump(Abnormal_model, f)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MrFeJBL6jctd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('Abnormal_model.pkl')\n",
        "files.download('xgb_model.pkl')"
      ],
      "metadata": {
        "id": "bOgxYN-6kFIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "eb614e37-6107-4e71-c2ec-ad21c3eec2e8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f4886d6-8bd4-4cc6-88be-1cbdf00fc9ed\", \"Abnormal_model.pkl\", 6415392)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_61a642df-184a-4cd0-b88e-61e15371d7da\", \"xgb_model.pkl\", 49195769)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Github === https://github.com/Shady-Abdelaziz/ECG-Classifications-Using-2-Models/tree/main\n",
        " App.py === https://github.com/Shady-Abdelaziz/ECG-Classifications-Using-2-Models/blob/main/App.py"
      ],
      "metadata": {
        "id": "K5l7-VQWghHl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "collapsed_sections": [
        "vEFYUcOJWE4y",
        "-7M5vRi8ZNM2",
        "1TLbLePuXUVn",
        "XfYlyi0TecUE",
        "7oFj2w0fpA8F",
        "tRbGu40LvG_B",
        "10rSEq7dja-I"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}